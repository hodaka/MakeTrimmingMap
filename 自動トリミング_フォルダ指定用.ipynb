{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "自動トリミング_フォルダ指定用.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "16dJ02XwXpfB_iSUIXf36IkjIFo0L2oci",
      "authorship_tag": "ABX9TyPNJ82NqzjZKpvxKLSvsqej",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hodaka/MakeTrimmingMap/blob/work/%E8%87%AA%E5%8B%95%E3%83%88%E3%83%AA%E3%83%9F%E3%83%B3%E3%82%B0_%E3%83%95%E3%82%A9%E3%83%AB%E3%83%80%E6%8C%87%E5%AE%9A%E7%94%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYhxvDgxyUiQ"
      },
      "source": [
        "# 人物を切り抜く準備としてのトリミングマップを作製するためのスクリプト\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "[参考URL](https://v-hramchenko.medium.com/how-to-cut-out-a-person-in-an-image-with-open-source-projects-e5e7f8798d5c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOMomEBfAqWh"
      },
      "source": [
        "1.   各種ライブラリのインポート"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQyKsMvLAWIh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e52da62-0f13-4e41-b316-4417bbccf4ff"
      },
      "source": [
        "# GPUサポートを備えたTensorライブラリ(PyTorch自体はインストール済みcolabにインストール済み？)\r\n",
        "import torch\r\n",
        "# ファイル操作用\r\n",
        "import os\r\n",
        "# 画像操作ライブラリ\r\n",
        "import cv2\r\n",
        "# ファイルパス操作用ライブラリ\r\n",
        "import glob\r\n",
        "# 機械学習用拡張ライブラリ\r\n",
        "import numpy as np\r\n",
        "# 計算結果をグラフィカルに表示するライブラリ\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "# セグメンテーション用ライブラリ\r\n",
        "from torchvision.models.segmentation import deeplabv3_resnet101\r\n",
        "# 画像の前処理や学習済みモデルなどを提供するエコシステム\r\n",
        "from torchvision import transforms\r\n",
        "# ファイル操作関連ライブラリ\r\n",
        "from google.colab import files\r\n",
        "# デバック用画像表示用ライブラリ\r\n",
        "from IPython.display import Image, display\r\n",
        "\r\n",
        "# 輪郭切り抜き用ライブラリ\r\n",
        "!git clone https://github.com/MarcoForte/FBA-Matting.git\r\n",
        "%cd FBA-Matting\r\n",
        "\r\n",
        "import sys\r\n",
        "sys.path.append(\"./FBA_Matting\")\r\n",
        "\r\n",
        "from demo import np_to_torch, pred, scale_input\r\n",
        "from dataloader import read_image, read_trimap\r\n",
        "from networks.models import build_model\r\n",
        "\r\n",
        "class Args:\r\n",
        "    encoder = 'resnet50_GN_WS'\r\n",
        "    decoder = 'fba_decoder'\r\n",
        "    weights = 'FBA.pth'\r\n",
        "\r\n",
        "args=Args()\r\n",
        "# 学習用のモデルを構築\r\n",
        "try:\r\n",
        "    model = build_model(args)\r\n",
        "except:\r\n",
        "    !gdown  https://drive.google.com/uc?id=1T_oiKDE_biWf2kqexMEN7ObWqtXAzbB1\r\n",
        "    model = build_model(args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'FBA-Matting'...\n",
            "remote: Enumerating objects: 119, done.\u001b[K\n",
            "remote: Counting objects: 100% (119/119), done.\u001b[K\n",
            "remote: Compressing objects: 100% (107/107), done.\u001b[K\n",
            "remote: Total 119 (delta 48), reused 47 (delta 10), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (119/119), 4.59 MiB | 8.11 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n",
            "/content/FBA-Matting\n",
            "modifying input layer to accept 11 channels\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1T_oiKDE_biWf2kqexMEN7ObWqtXAzbB1\n",
            "To: /content/FBA-Matting/FBA.pth\n",
            "139MB [00:01, 124MB/s] \n",
            "modifying input layer to accept 11 channels\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OqR7rnXBuhH"
      },
      "source": [
        "2.   グーグルドライブをマウント\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB8vimbjcosF"
      },
      "source": [
        "drive.mount('/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyH3L8plB8PN"
      },
      "source": [
        "# 対象を取得するセグメンテーション用ライブラリを定義\r\n",
        "def make_deeplab(device):\r\n",
        "    deeplab = deeplabv3_resnet101(pretrained=True).to(device)\r\n",
        "    deeplab.eval()\r\n",
        "    return deeplab\r\n",
        "\r\n",
        "device = torch.device(\"cpu\")\r\n",
        "deeplab = make_deeplab(device)\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpU9OfZIrXk6"
      },
      "source": [
        "#@title 読み取り対象のフォルダパスを指定\r\n",
        "\r\n",
        "#@markdown 読み取り対象の画像が保存されているフォルダ\r\n",
        "read_path = \"/drive/MyDrive/ImageData/NamioHarukawa_base\"  #@param {type:\"string\"}\r\n",
        "\r\n",
        "#@markdown 読み取り対象のフォルダに作成する出力用サブフォルダ名\r\n",
        "# 出力対象のフォルダパスを指定\r\n",
        "outputFoldrName = \"/ResultOutput/\" #@param {type:\"string\"}\r\n",
        "output_path = read_path + outputFoldrName"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbZaIKWdckn9"
      },
      "source": [
        "#ディレクトリ作成(なければ)\r\n",
        "if not os.path.exists(output_path):\r\n",
        "  os.makedirs(output_path)\r\n",
        "\r\n",
        "for idx,imageFilePath in enumerate(glob.glob(read_path + \"/*.*\")):\r\n",
        "  print(imageFilePath)\r\n",
        "  img_orig = cv2.imread(imageFilePath, 1)\r\n",
        "  k = min(1.0, 1024/max(img_orig.shape[0], img_orig.shape[1]))\r\n",
        "  img = cv2.resize(img_orig, None, fx=k, fy=k, interpolation=cv2.INTER_LANCZOS4)\r\n",
        "\r\n",
        "  deeplab_preprocess = transforms.Compose([\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\r\n",
        "  ])\r\n",
        "\r\n",
        "  def apply_deeplab(deeplab, img, device):\r\n",
        "    input_tensor = deeplab_preprocess(img)\r\n",
        "    input_batch = input_tensor.unsqueeze(0)\r\n",
        "    with torch.no_grad():\r\n",
        "        output = deeplab(input_batch.to(device))['out'][0]\r\n",
        "    output_predictions = output.argmax(0).cpu().numpy()\r\n",
        "    # 15が人を表しているらしい…\r\n",
        "    return (output_predictions == 15)\r\n",
        "\r\n",
        "  mask = apply_deeplab(deeplab, img, device)\r\n",
        "  \r\n",
        "  trimap = np.zeros((mask.shape[0], mask.shape[1], 2))\r\n",
        "  trimap[:, :, 1] = mask > 0\r\n",
        "  trimap[:, :, 0] = mask == 0\r\n",
        "  kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(25,25))\r\n",
        "\r\n",
        "  trimap[:, :, 0] = cv2.erode(trimap[:, :, 0], kernel)\r\n",
        "  trimap[:, :, 1] = cv2.erode(trimap[:, :, 1], kernel)\r\n",
        "\r\n",
        "  fg, bg, alpha = pred((img/255.0)[:, :, ::-1], trimap, model)\r\n",
        "\r\n",
        "  img_ = img_orig.astype(np.float32)/255\r\n",
        "  alpha_ = cv2.resize(alpha, (img_.shape[1], img_.shape[0]), cv2.INTER_LANCZOS4)\r\n",
        "  fg_alpha = np.concatenate([img_, alpha_[:, :, np.newaxis]], axis=2)\r\n",
        "  outPath = output_path + \"trimed_\"+ str(idx) + \".png\"\r\n",
        "  print(outPath)\r\n",
        "  # PNGファイルとして保存しないと透過設定が有効にならない？\r\n",
        "  cv2.imwrite(outPath, (fg_alpha*255).astype(np.uint8))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}