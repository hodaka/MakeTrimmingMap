{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "自動トリミング.ipynb",
      "provenance": [],
      "mount_file_id": "12DWBHQ8Um1DYlivaJ-oieyqJaFLc5Myb",
      "authorship_tag": "ABX9TyOcquEAuaiibsh+XWkfV78L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hodaka/MakeTrimmingMap/blob/work/%E8%87%AA%E5%8B%95%E3%83%88%E3%83%AA%E3%83%9F%E3%83%B3%E3%82%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYhxvDgxyUiQ"
      },
      "source": [
        "# 人物を切り抜く準備としてのトリミングマップを作製するためのスクリプト\r\n",
        "\r\n",
        "\r\n",
        "---\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx6iMtMzfo-s"
      },
      "source": [
        "import torch\r\n",
        "import os\r\n",
        "import cv2\r\n",
        "import glob\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "from torchvision.models.segmentation import deeplabv3_resnet101\r\n",
        "from torchvision import transforms\r\n",
        "from IPython.display import Image\r\n",
        "from google.colab import files\r\n",
        "from IPython.display import Image, display\r\n",
        "\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/gdrive')\r\n",
        "\r\n",
        "def make_deeplab(device):\r\n",
        "    deeplab = deeplabv3_resnet101(pretrained=True).to(device)\r\n",
        "    deeplab.eval()\r\n",
        "    return deeplab\r\n",
        "\r\n",
        "deeplab_preprocess = transforms.Compose([\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\r\n",
        "])\r\n",
        "\r\n",
        "def apply_deeplab(deeplab, img, device):\r\n",
        "  input_tensor = deeplab_preprocess(img)\r\n",
        "  input_batch = input_tensor.unsqueeze(0)\r\n",
        "  with torch.no_grad():\r\n",
        "      output = deeplab(input_batch.to(device))['out'][0]\r\n",
        "  output_predictions = output.argmax(0).cpu().numpy()\r\n",
        "  return (output_predictions == 15)\r\n",
        "\r\n",
        "# 境界を定義したトリミングマップを作成\r\n",
        "def make_trimap(masking_image):\r\n",
        "  print('masking_image: ', masking_image)\r\n",
        "  trimap = np.zeros((masking_image.shape[0], masking_image.shape[1], 2))\r\n",
        "  trimap[:, :, 1] = masking_image > 0\r\n",
        "  trimap[:, :, 0] = masking_image == 0\r\n",
        "  kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(12,12))\r\n",
        "  trimap[:, :, 0] = cv2.erode(trimap[:, :, 0], kernel)\r\n",
        "  trimap[:, :, 1] = cv2.erode(trimap[:, :, 1], kernel)\r\n",
        "  return  trimap[:,:,1] + (1-np.sum(trimap,-1))/2\r\n",
        "\r\n",
        "# 読み取り対象のフォルダパスを指定\r\n",
        "read_path = \"/gdrive/MyDrive/ImageData/NamioHarukawaNoChoice\"\r\n",
        "# 出力対象のフォルダパスを指定\r\n",
        "output_path = read_path + \"/ResultTrimap/\"\r\n",
        "\r\n",
        "#ディレクトリ作成(なければ)\r\n",
        "if not os.path.exists(output_path):\r\n",
        "   os.makedirs(output_path)\r\n",
        "\r\n",
        "\r\n",
        "!git clone https://github.com/MarcoForte/FBA-Matting.git\r\n",
        "%cd FBA-Matting\r\n",
        "\r\n",
        "from demo import np_to_torch, pred, scale_input\r\n",
        "from dataloader import read_image, read_trimap\r\n",
        "from networks.models import build_model\r\n",
        "\r\n",
        "class Args:\r\n",
        "  encoder = 'resnet50_GN_WS'\r\n",
        "  decoder = 'fba_decoder'\r\n",
        "  weights = 'FBA.pth'\r\n",
        "args=Args()\r\n",
        "try:\r\n",
        "    model = build_model(args)\r\n",
        "except:\r\n",
        "    !gdown  https://drive.google.com/uc?id=1T_oiKDE_biWf2kqexMEN7ObWqtXAzbB1\r\n",
        "    model = build_model(args)\r\n",
        "\r\n",
        "print('モデル作成')\r\n",
        "\r\n",
        "device = torch.device(\"cpu\")\r\n",
        "deeplab = make_deeplab(device)\r\n",
        "\r\n",
        "print('ループ開始')\r\n",
        "\r\n",
        "for idx,imageFilePath in enumerate(glob.glob(read_path + \"/*.*\")):\r\n",
        "  print('targetPath:' , imageFilePath)\r\n",
        "  # 画像の読み込み\r\n",
        "  img = cv2.imread(imageFilePath,1)  \r\n",
        "  # 輪郭相当のマスクデータを作成\r\n",
        "  mask_img = apply_deeplab(deeplab, img, device)\r\n",
        "  # 境界を定義したトリミングマップを作成\r\n",
        "  print('masking_image: ')    \r\n",
        "  trimap = np.zeros((mask_img.shape[0], mask_img.shape[1], 2))\r\n",
        "  trimap[:, :, 1] = mask_img > 0\r\n",
        "  trimap[:, :, 0] = mask_img == 0\r\n",
        "  kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(12,12))\r\n",
        "  trimap[:, :, 0] = cv2.erode(trimap[:, :, 0], kernel)\r\n",
        "  trimap[:, :, 1] = cv2.erode(trimap[:, :, 1], kernel)  \r\n",
        "  trimap_im = trimap[:,:,1] + (1-np.sum(trimap,-1))/2\r\n",
        "\r\n",
        "  print('トリミングマップ完成')   \r\n",
        "  out_color_trimap_path = output_path + 'trimap_c_' + str(idx) + '.jpg';\r\n",
        "  plt.imsave(out_color_trimap_path,trimap_im)\r\n",
        "  color_trimap = cv2.imread(out_color_trimap_path,1)  \r\n",
        "  gray_trimap = cv2.cvtColor(color_trimap, cv2.COLOR_BGR2GRAY)\r\n",
        "  out_gray_trimap_path = output_path + 'trimap_g_' + str(idx) + '.jpg';  \r\n",
        "  plt.imsave(out_gray_trimap_path,gray_trimap)\r\n",
        "  target_image = read_image(imageFilePath)\r\n",
        "  target_trimap = read_trimap(out_gray_trimap_path)\r\n",
        "  foreground, background, alpha = pred(target_image, target_trimap, model)\r\n",
        "  out_result_path = output_path + 'result_' + str(idx) + '.jpg';\r\n",
        "  plt.imsave(out_result_path,foreground)  \r\n",
        "\r\n",
        "print('処理完了')  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}